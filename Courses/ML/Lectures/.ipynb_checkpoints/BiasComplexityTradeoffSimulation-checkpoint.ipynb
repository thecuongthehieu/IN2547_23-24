{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix how many hypotheses we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hypotheses = 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix a random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assign a generalization error to each of our hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_errors = np.random.rand(num_hypotheses)+0.2*np.ones(num_hypotheses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how they perform on random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples_vector:  [10. 10. 10. ... 10. 10. 10.]\n",
      "Best training error: 0.0\n",
      "Index of ERM hypothesis: 10\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "num_samples_vector = num_samples*np.ones(num_hypotheses) # len = num_hypotheses\n",
    "\n",
    "for i in range(len(num_samples_vector)):\n",
    "    num_samples_vector[i] = int(num_samples_vector[i])\n",
    "\n",
    "# print(\"num_samples_vector: \", num_samples_vector)\n",
    "\n",
    "outcomes = np.zeros(num_hypotheses)\n",
    "\n",
    "ERM_hyp = -1\n",
    "minimum_ER = 1.\n",
    "for i in range(len(num_samples_vector)):\n",
    "    outcomes[i] = np.random.binomial(num_samples_vector[i], min(gen_errors[i],1.0))/num_samples\n",
    "    # print(\"outcomes[\" + str(i) + \"]\", outcomes[i])\n",
    "    if (outcomes[i] < minimum_ER):\n",
    "        minimum_ER = outcomes[i]\n",
    "        ERM_hyp = i\n",
    "    \n",
    "\n",
    "#see what is the best training error\n",
    "print(\"Best training error: \"+str(minimum_ER))\n",
    "print(\"Index of ERM hypothesis: \"+str(ERM_hyp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best generalization error: 0.20000027426658157\n"
     ]
    }
   ],
   "source": [
    "print(\"Best generalization error: \"+str(min(gen_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalization error of ERM hypothesis: 0.2538063897063029\n"
     ]
    }
   ],
   "source": [
    "print(\"Generalization error of ERM hypothesis: \"+str(gen_errors[ERM_hyp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
