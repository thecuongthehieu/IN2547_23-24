{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Neural Networks: Regression on House Pricing Dataset\n",
    "We consider a reduced version of a dataset containing house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.\n",
    "\n",
    "https://www.kaggle.com/harlfoxem/housesalesprediction\n",
    "\n",
    "For each house we know 18 house features (e.g., number of bedrooms, number of bathrooms, etc.) plus its price, that is what we would like to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#put here your ``numero di matricola''\n",
    "numero_di_matricola = 1 # COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert your ID number (\"numero di matricola\") below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#put here your ``numero di matricola''\n",
    "numero_di_matricola = 1 # COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import all packages needed\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data, remove data samples/points with missing values (NaN) and take a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.164000e+03</td>\n",
       "      <td>3.164000e+03</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3.164000e+03</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.645240e+09</td>\n",
       "      <td>5.354358e+05</td>\n",
       "      <td>3.381163</td>\n",
       "      <td>2.071903</td>\n",
       "      <td>2070.027813</td>\n",
       "      <td>1.525054e+04</td>\n",
       "      <td>1.434893</td>\n",
       "      <td>0.009798</td>\n",
       "      <td>0.244311</td>\n",
       "      <td>3.459229</td>\n",
       "      <td>7.615676</td>\n",
       "      <td>1761.252212</td>\n",
       "      <td>308.775601</td>\n",
       "      <td>1967.489254</td>\n",
       "      <td>94.668774</td>\n",
       "      <td>98077.125158</td>\n",
       "      <td>47.557868</td>\n",
       "      <td>-122.212337</td>\n",
       "      <td>1982.544564</td>\n",
       "      <td>13176.302465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.854203e+09</td>\n",
       "      <td>3.809004e+05</td>\n",
       "      <td>0.895472</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>920.251879</td>\n",
       "      <td>4.254457e+04</td>\n",
       "      <td>0.507792</td>\n",
       "      <td>0.098513</td>\n",
       "      <td>0.776298</td>\n",
       "      <td>0.682592</td>\n",
       "      <td>1.166324</td>\n",
       "      <td>815.934864</td>\n",
       "      <td>458.977904</td>\n",
       "      <td>28.095275</td>\n",
       "      <td>424.439427</td>\n",
       "      <td>54.172937</td>\n",
       "      <td>0.140789</td>\n",
       "      <td>0.139577</td>\n",
       "      <td>686.256670</td>\n",
       "      <td>25413.180755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000102e+06</td>\n",
       "      <td>7.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>6.490000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98001.000000</td>\n",
       "      <td>47.177500</td>\n",
       "      <td>-122.514000</td>\n",
       "      <td>620.000000</td>\n",
       "      <td>660.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.199775e+09</td>\n",
       "      <td>3.150000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1430.000000</td>\n",
       "      <td>5.453750e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98032.000000</td>\n",
       "      <td>47.459575</td>\n",
       "      <td>-122.324250</td>\n",
       "      <td>1480.000000</td>\n",
       "      <td>5429.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.027701e+09</td>\n",
       "      <td>4.450000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1910.000000</td>\n",
       "      <td>8.000000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1545.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1969.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98059.000000</td>\n",
       "      <td>47.572500</td>\n",
       "      <td>-122.226000</td>\n",
       "      <td>1830.000000</td>\n",
       "      <td>7873.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.358175e+09</td>\n",
       "      <td>6.402500e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>1.122250e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2150.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>1990.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98117.000000</td>\n",
       "      <td>47.680250</td>\n",
       "      <td>-122.124000</td>\n",
       "      <td>2360.000000</td>\n",
       "      <td>10408.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.839301e+09</td>\n",
       "      <td>5.350000e+06</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8010.000000</td>\n",
       "      <td>1.651359e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6720.000000</td>\n",
       "      <td>2620.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>98199.000000</td>\n",
       "      <td>47.777600</td>\n",
       "      <td>-121.315000</td>\n",
       "      <td>5790.000000</td>\n",
       "      <td>425581.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         price     bedrooms    bathrooms  sqft_living  \\\n",
       "count  3.164000e+03  3.164000e+03  3164.000000  3164.000000  3164.000000   \n",
       "mean   4.645240e+09  5.354358e+05     3.381163     2.071903  2070.027813   \n",
       "std    2.854203e+09  3.809004e+05     0.895472     0.768212   920.251879   \n",
       "min    1.000102e+06  7.500000e+04     0.000000     0.000000   380.000000   \n",
       "25%    2.199775e+09  3.150000e+05     3.000000     1.500000  1430.000000   \n",
       "50%    4.027701e+09  4.450000e+05     3.000000     2.000000  1910.000000   \n",
       "75%    7.358175e+09  6.402500e+05     4.000000     2.500000  2500.000000   \n",
       "max    9.839301e+09  5.350000e+06     8.000000     6.000000  8010.000000   \n",
       "\n",
       "           sqft_lot       floors   waterfront         view    condition  \\\n",
       "count  3.164000e+03  3164.000000  3164.000000  3164.000000  3164.000000   \n",
       "mean   1.525054e+04     1.434893     0.009798     0.244311     3.459229   \n",
       "std    4.254457e+04     0.507792     0.098513     0.776298     0.682592   \n",
       "min    6.490000e+02     1.000000     0.000000     0.000000     1.000000   \n",
       "25%    5.453750e+03     1.000000     0.000000     0.000000     3.000000   \n",
       "50%    8.000000e+03     1.000000     0.000000     0.000000     3.000000   \n",
       "75%    1.122250e+04     2.000000     0.000000     0.000000     4.000000   \n",
       "max    1.651359e+06     3.500000     1.000000     4.000000     5.000000   \n",
       "\n",
       "             grade   sqft_above  sqft_basement     yr_built  yr_renovated  \\\n",
       "count  3164.000000  3164.000000    3164.000000  3164.000000   3164.000000   \n",
       "mean      7.615676  1761.252212     308.775601  1967.489254     94.668774   \n",
       "std       1.166324   815.934864     458.977904    28.095275    424.439427   \n",
       "min       3.000000   380.000000       0.000000  1900.000000      0.000000   \n",
       "25%       7.000000  1190.000000       0.000000  1950.000000      0.000000   \n",
       "50%       7.000000  1545.000000       0.000000  1969.000000      0.000000   \n",
       "75%       8.000000  2150.000000     600.000000  1990.000000      0.000000   \n",
       "max      12.000000  6720.000000    2620.000000  2015.000000   2015.000000   \n",
       "\n",
       "            zipcode          lat         long  sqft_living15     sqft_lot15  \n",
       "count   3164.000000  3164.000000  3164.000000    3164.000000    3164.000000  \n",
       "mean   98077.125158    47.557868  -122.212337    1982.544564   13176.302465  \n",
       "std       54.172937     0.140789     0.139577     686.256670   25413.180755  \n",
       "min    98001.000000    47.177500  -122.514000     620.000000     660.000000  \n",
       "25%    98032.000000    47.459575  -122.324250    1480.000000    5429.500000  \n",
       "50%    98059.000000    47.572500  -122.226000    1830.000000    7873.000000  \n",
       "75%    98117.000000    47.680250  -122.124000    2360.000000   10408.250000  \n",
       "max    98199.000000    47.777600  -121.315000    5790.000000  425581.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data\n",
    "df = pd.read_csv('kc_house_data.csv', sep = ',')\n",
    "\n",
    "#remove the data samples with missing values (NaN)\n",
    "df = df.dropna() \n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract input and output data. We want to predict the price by using features other than id as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of data: 3164\n"
     ]
    }
   ],
   "source": [
    "Data = df.values\n",
    "# m = number of input samples\n",
    "m = Data.shape[0]\n",
    "print(\"Amount of data:\",m)\n",
    "Y = Data[:m,2]\n",
    "X = Data[:m,3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "We split the data into 3 parts: one will be used for training and choosing the parameters, one for choosing among different models, and one for testing. The part for training and choosing the parameters will consist of $2/3$ of all samples, the one for choosing among different models will consist of $1/6$ of all samples, while the other part consists of the remaining $1/6$-th of all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of data for training and deciding parameters: 2109\n",
      "Amount of data for validation (choosing among different models): 527\n",
      "Amount of data for test: 528\n"
     ]
    }
   ],
   "source": [
    "# Split data into train (2/3 of samples), validation (1/6 of samples), and test data (the rest)\n",
    "m_train = int(2./3.*m)\n",
    "m_val = int((m-m_train)/2.)\n",
    "m_test = m - m_train - m_val\n",
    "print(\"Amount of data for training and deciding parameters:\",m_train)\n",
    "print(\"Amount of data for validation (choosing among different models):\",m_val)\n",
    "print(\"Amount of data for test:\",m_test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain_and_val, Xtest, Ytrain_and_val, Ytest = train_test_split(X, Y, test_size=m_test/m, random_state=numero_di_matricola)\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(Xtrain_and_val, Ytrain_and_val, test_size=m_val/(m_train+m_val), random_state=numero_di_matricola)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's standardize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data pre-processing\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
    "Xtrain_scaled = scaler.transform(Xtrain)\n",
    "Xtrain_and_val_scaled = scaler.transform(Xtrain_and_val)\n",
    "Xval_scaled = scaler.transform(Xval)\n",
    "Xtest_scaled = scaler.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "Let's start by learning a simple neural network with 1 hidden node.\n",
    "Note: we are going to use the input parameter solver='lbfgs' and random_state=numero_di_matricola to fix the random seed (so results are reproducible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - coeff. det. on training data:  0.26394830238482436\n",
      "1 - coeff. det. on validation data:  0.3040543646853412\n",
      "[array([[-214.89537876],\n",
      "       [ 269.68024917],\n",
      "       [ 524.7704258 ],\n",
      "       [ -60.81284604],\n",
      "       [   4.05087088],\n",
      "       [ 712.42928594],\n",
      "       [ 294.92981517],\n",
      "       [ 136.76215235],\n",
      "       [ 817.57014025],\n",
      "       [ 494.13427771],\n",
      "       [ 163.88996536],\n",
      "       [-583.21542093],\n",
      "       [  38.03555851],\n",
      "       [-203.94726396],\n",
      "       [ 601.25801877],\n",
      "       [-142.47633036],\n",
      "       [ 147.37660515],\n",
      "       [ -27.04871472]]), array([[140.85769064]])]\n",
      "[array([3801.74832393]), array([-53.52995482])]\n"
     ]
    }
   ],
   "source": [
    "#let's load the MLPRegressor\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#let's define the model\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(1, ), solver='lbfgs', random_state=numero_di_matricola)\n",
    "\n",
    "#let's learn the model on training data\n",
    "mlp.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"1 - coeff. det. on training data: \",1. - mlp.score(Xtrain_scaled, Ytrain))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"1 - coeff. det. on validation data: \",1. - mlp.score(Xval_scaled, Yval))\n",
    "\n",
    "#let's print the coefficients of the model for the input nodes (but not the bias)\n",
    "print(mlp.coefs_)\n",
    "\n",
    "#let's print the coefficient for the bias (i.e., the bias)\n",
    "print(mlp.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks vs Linear Models\n",
    "\n",
    "Let's learn a linear model on the other same data and compare the results with the simple NN above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - coeff. det. on training data:  0.2653594216072852\n",
      "1 - coeff. det. on validation data:  0.3115400506517969\n",
      "[-31303.71909156  35848.45081517  74506.78099995  -8012.41104949\n",
      "    671.23713588 100205.53195594  41671.19028923  19507.84532115\n",
      " 111331.50566184  69959.22677526  23468.73219785 -78236.93092911\n",
      "   6535.34729956 -28197.21476235  83701.76486765 -21647.26671149\n",
      "  22056.22833416  -2002.69401407]\n",
      "536831.9203413766\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "LR = linear_model.LinearRegression()\n",
    "\n",
    "LR.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"1 - coeff. det. on training data: \",1. - LR.score(Xtrain_scaled, Ytrain))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"1 - coeff. det. on validation data: \",1. - LR.score(Xval_scaled, Yval))\n",
    "\n",
    "print(LR.coef_)\n",
    "print(LR.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a way to make a NN network learn a linear model?\n",
    "\n",
    "Let's first check what is the loss used by MLPRegressor..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - coefficient of determination on training data:0.26535942166590454\n",
      "1 - coefficient of determination on validation data:0.31153906582827584\n",
      "[array([[  51.55070235],\n",
      "       [ -59.02846704],\n",
      "       [-122.96939596],\n",
      "       [  13.19466306],\n",
      "       [  -1.10694448],\n",
      "       [-165.016906  ],\n",
      "       [ -68.62491747],\n",
      "       [ -32.12596414],\n",
      "       [-183.34020234],\n",
      "       [-114.96558392],\n",
      "       [ -38.51551396],\n",
      "       [ 128.83877577],\n",
      "       [ -10.76237595],\n",
      "       [  46.43749972],\n",
      "       [-137.83874569],\n",
      "       [  35.64844107],\n",
      "       [ -36.32214078],\n",
      "       [   3.29740834]]), array([[-607.24280969]])]\n",
      "[array([-883.44724722]), array([365.29153421])]\n"
     ]
    }
   ],
   "source": [
    "#let's write the code to learn a linear model with NN: how? \n",
    "\n",
    "mlp_lr = MLPRegressor(hidden_layer_sizes=(1, ), solver='lbfgs', random_state=numero_di_matricola, activation='identity')\n",
    "\n",
    "#let's learn the model on training data\n",
    "mlp_lr.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"1 - coefficient of determination on training data:\"+str(1 - mlp_lr.score(Xtrain_scaled,Ytrain)))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"1 - coefficient of determination on validation data:\"+str(1 - mlp_lr.score(Xval_scaled,Yval)))\n",
    "\n",
    "#let's print the coefficients of the model for the input nodes (but not the bias)\n",
    "print(mlp_lr.coefs_)\n",
    "\n",
    "#let's print the coefficient for the bias (i.e., the bias)\n",
    "print(mlp_lr.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is an $\\ell_2$ regularization term in MLPRegressor. What about making it smaller?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - coefficient of determination on training data:0.26535942166590454\n",
      "1 - coefficient of determination on validation data:0.31153906582851487\n",
      "[array([[  51.55070235],\n",
      "       [ -59.02846704],\n",
      "       [-122.96939596],\n",
      "       [  13.19466306],\n",
      "       [  -1.10694448],\n",
      "       [-165.016906  ],\n",
      "       [ -68.62491747],\n",
      "       [ -32.12596414],\n",
      "       [-183.34020234],\n",
      "       [-114.96558392],\n",
      "       [ -38.51551396],\n",
      "       [ 128.83877577],\n",
      "       [ -10.76237595],\n",
      "       [  46.43749972],\n",
      "       [-137.83874569],\n",
      "       [  35.64844107],\n",
      "       [ -36.32214078],\n",
      "       [   3.29740834]]), array([[-607.24280969]])]\n",
      "[array([-883.44724722]), array([365.29153421])]\n"
     ]
    }
   ],
   "source": [
    "#let's write the code to learn a linear model with NN: how? \n",
    "\n",
    "mlp_lr = MLPRegressor(hidden_layer_sizes=(1, ), solver='lbfgs', random_state=numero_di_matricola, activation='identity', alpha=1e-20)\n",
    "\n",
    "#let's learn the model on training data\n",
    "mlp_lr.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"1 - coefficient of determination on training data:\"+str(1 - mlp_lr.score(Xtrain_scaled,Ytrain)))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"1 - coefficient of determination on validation data:\"+str(1 - mlp_lr.score(Xval_scaled,Yval)))\n",
    "\n",
    "#let's print the coefficients of the model for the input nodes (but not the bias)\n",
    "print(mlp_lr.coefs_)\n",
    "\n",
    "#let's print the coefficient for the bias (i.e., the bias)\n",
    "print(mlp_lr.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Complex NNs\n",
    "\n",
    "Let's try more complex NN, for example increasing the number of nodes in the only hidden layer, or increasing the number of hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a NN with 2 nodes in the only hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - coefficient of determination on training data:0.18062204729898812\n",
      "1 - coefficient of determination on validation data:0.20740336169260698\n",
      "[array([[  91.02546219,  -33.27608287],\n",
      "       [ 120.42553462,   39.34084156],\n",
      "       [  85.91890553,   72.98647233],\n",
      "       [-271.77204346,   28.29799259],\n",
      "       [ -30.70886702,   17.82803252],\n",
      "       [ 197.57397911,   25.89043456],\n",
      "       [  34.91678814,   37.55628571],\n",
      "       [  96.98115133,   25.68560859],\n",
      "       [ 312.80447016,  132.75177186],\n",
      "       [  85.17119398,   68.79247395],\n",
      "       [  19.29800302,   23.33098753],\n",
      "       [-217.57993132,  -81.10873331],\n",
      "       [  -3.45129149,   20.168397  ],\n",
      "       [-300.96669106,  -26.39828985],\n",
      "       [ 305.2000606 ,  144.62958297],\n",
      "       [-463.25887306,  -16.42945193],\n",
      "       [ 193.67060699,   53.02179413],\n",
      "       [-241.36463256,  -11.18173072]]), array([[615.21891754],\n",
      "       [548.8759815 ]])]\n",
      "[array([-1049.80825139,   897.57600271]), array([725.96714422])]\n"
     ]
    }
   ],
   "source": [
    "#let's build a NN with 2 nodes in the only hidden layer\n",
    "\n",
    "#let's define the model\n",
    "mlp_1h2n = MLPRegressor(hidden_layer_sizes=(2, ), solver='lbfgs', random_state=numero_di_matricola)\n",
    "\n",
    "#let's learn the model on training data\n",
    "mlp_1h2n.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"1 - coefficient of determination on training data:\"+str(1 - mlp_1h2n.score(Xtrain_scaled,Ytrain)))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"1 - coefficient of determination on validation data:\"+str(1 - mlp_1h2n.score(Xval_scaled,Yval)))\n",
    "\n",
    "#let's print the coefficients of the model for the input nodes (but not the bias)\n",
    "print(mlp_1h2n.coefs_)\n",
    "\n",
    "#let's print the coefficient for the bias (i.e., the bias)\n",
    "print(mlp_1h2n.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a NN with 5 nodes in the only hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - coefficient of determination on training data:0.13703265994636593\n",
      "1 - coefficient of determination on validation data:0.26655927513578215\n",
      "[array([[ -315.30434744,    51.7845602 ,    58.62236991,   154.0552365 ,\n",
      "          -10.5249514 ],\n",
      "       [  937.22062287,   695.46330768,    87.69237678,  -187.42587367,\n",
      "         -116.82132396],\n",
      "       [ -359.34724738,    -4.51541138,   209.92618971,  -390.39327786,\n",
      "          438.23812309],\n",
      "       [  447.99802835,  -838.72298207,  -109.76160246,  -772.2469024 ,\n",
      "           66.23782525],\n",
      "       [  442.77984217,  -135.19252426,   416.62293963,   242.25195779,\n",
      "         -193.72979054],\n",
      "       [ -856.62862239,   321.80003932,   885.28941211,  -547.21803084,\n",
      "         -257.29856447],\n",
      "       [ -230.61908197,   326.46341444,  -232.98750674,  -159.22807515,\n",
      "          201.21955686],\n",
      "       [ -453.93371676,   587.78613038,  -145.56822395,   527.91054793,\n",
      "           31.53234978],\n",
      "       [   17.17384295,   922.54016171,   878.85667145,   231.26670122,\n",
      "          430.08111608],\n",
      "       [ -428.07197329,   177.95758634,   -11.44567568,  -430.96101023,\n",
      "          445.89996666],\n",
      "       [   50.93819694,  -331.56342612,   444.60370467,    -7.50022342,\n",
      "           75.86391879],\n",
      "       [ 1082.45005885,  -494.88434452,  -422.73158921, -1431.54691089,\n",
      "         -149.92834805],\n",
      "       [ -354.86005065,   471.61841965, -1889.14105133, -1043.13920132,\n",
      "          346.37018715],\n",
      "       [  380.5385175 , -1694.11332152,   123.17027177,  -216.52192978,\n",
      "         -143.38822943],\n",
      "       [ -177.27140333,   747.46639648,   861.46023863,   -72.28393165,\n",
      "          579.7442653 ],\n",
      "       [  562.00905942, -1218.07055963,  -885.81954168,  -141.93733874,\n",
      "         -196.14372432],\n",
      "       [-1052.02648197,   552.31457601,   117.07522394,   834.93519342,\n",
      "          335.25766404],\n",
      "       [  201.02432718,   302.23733894, -1037.43891001,   394.34274441,\n",
      "         -181.65379642]]), array([[ 49.23310425],\n",
      "       [132.15572293],\n",
      "       [227.98679704],\n",
      "       [ 73.68383971],\n",
      "       [156.65610119]])]\n",
      "[array([ 2338.07747307, -3202.60436283, -3647.27156272,   382.99115624,\n",
      "        1842.46958506]), array([322.19618372])]\n"
     ]
    }
   ],
   "source": [
    "#let's build a NN with 5 nodes in the only hidden layer\n",
    "#mlp_1h5n = MLPRegressor(hidden_layer_sizes=(5, ), solver='lbfgs', random_state=numero_di_matricola)\n",
    "#after warning shows up\n",
    "mlp_1h5n = MLPRegressor(hidden_layer_sizes=(5, ), solver='lbfgs', random_state=numero_di_matricola, max_iter=2000)\n",
    "\n",
    "#let's learn the model on training data\n",
    "mlp_1h5n.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"1 - coefficient of determination on training data:\"+str(1 - mlp_1h5n.score(Xtrain_scaled,Ytrain)))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"1 - coefficient of determination on validation data:\"+str(1 - mlp_1h5n.score(Xval_scaled,Yval)))\n",
    "\n",
    "#let's print the coefficients of the model for the input nodes (but not the bias)\n",
    "print(mlp_1h5n.coefs_)\n",
    "\n",
    "#let's print the coefficient for the bias (i.e., the bias)\n",
    "print(mlp_1h5n.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that with a smaller number of iterations we had a larger error on training set but a smaller error on validation data -> \"early stopping is a form of regularization\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a NN with 10 nodes in the only hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - coefficient of determination on training data:0.12100449380223133\n",
      "1 - coefficient of determination on validation data:0.3093641567850296\n",
      "[array([[ 1.41153020e+02, -7.92118639e+00, -6.81225750e+01,\n",
      "         8.51439247e+01,  4.89097020e+01, -5.91401990e+01,\n",
      "         3.46987992e+01, -2.61767110e+01, -5.22035252e+01,\n",
      "         1.91685738e+02],\n",
      "       [ 1.58466634e+01, -6.20523185e+01,  1.01618733e+02,\n",
      "         5.34879133e+01, -9.21460359e+01,  4.09740931e+02,\n",
      "         2.90964528e+02, -2.75096845e+00,  1.14179204e+02,\n",
      "        -1.56481797e+02],\n",
      "       [-1.29726783e+02,  3.58905348e+01,  2.46596964e+02,\n",
      "         1.60306905e+01, -1.78390257e+02,  1.75216588e+02,\n",
      "        -1.97011257e+02, -7.46748230e+00,  1.11411585e+02,\n",
      "        -1.66435716e+02],\n",
      "       [ 1.91858020e+02,  3.91216932e+01,  7.07075995e+01,\n",
      "        -1.90881059e+02, -9.77994418e+01, -1.18028464e+01,\n",
      "        -2.07881958e+02, -1.24909867e+02, -3.83693919e+01,\n",
      "        -5.02578334e+02],\n",
      "       [-5.35652224e+02,  5.61128983e+02, -1.82641960e+02,\n",
      "         7.19030949e+01,  1.93379047e+02, -2.24756941e+01,\n",
      "        -1.79707381e+02,  2.01220687e+02,  1.81012913e+02,\n",
      "        -5.84347921e+02],\n",
      "       [ 2.78706695e+02, -2.00743397e+02, -1.23634297e+02,\n",
      "         1.07889874e+02, -3.50440474e+02,  1.31702254e+02,\n",
      "        -2.23251071e+02, -8.10270160e+01,  2.19933530e+02,\n",
      "         4.61176616e+02],\n",
      "       [-2.43472051e+01, -1.85684780e+02,  1.73504147e+01,\n",
      "         1.23529352e+02,  1.44378348e+02, -1.62373859e+02,\n",
      "         1.40396973e+02, -6.99021241e+01, -7.54688231e+01,\n",
      "         2.33272781e+01],\n",
      "       [-9.29717880e+01, -3.02655388e+02, -6.46768807e+01,\n",
      "         8.30235492e+01,  3.51959718e+02,  3.49815620e+02,\n",
      "         6.79578094e+00,  9.28169027e+01,  1.12147526e+02,\n",
      "        -1.15879307e+02],\n",
      "       [-1.04904991e+02, -1.22245684e+02,  2.14640663e+02,\n",
      "         3.66611107e+02,  1.09300680e+02,  2.77123639e+02,\n",
      "         1.96784056e+02, -2.14109225e+01,  1.35026726e+02,\n",
      "         4.39314343e+02],\n",
      "       [-2.38934928e+01, -7.54454990e+00,  2.29382687e+02,\n",
      "         6.43030691e+01, -1.62118610e+02,  1.30073525e+02,\n",
      "        -3.87306297e+01, -2.27884311e+01,  1.25451096e+01,\n",
      "        -1.85012771e+02],\n",
      "       [-2.19954800e+02,  8.60713129e+01,  8.22231934e+01,\n",
      "        -8.47037096e+01, -6.64419702e+01,  1.16652071e+02,\n",
      "        -3.26514261e+02,  2.76666761e+01,  2.02158031e+02,\n",
      "        -3.18139933e-01],\n",
      "       [ 2.85457583e+02,  1.71453074e+02,  1.46929102e+02,\n",
      "        -3.07884294e+02, -4.11437245e+02,  2.08672264e+01,\n",
      "         1.37900495e+02, -1.72224512e+02,  1.66282415e+02,\n",
      "        -9.23860849e+02],\n",
      "       [-9.00747568e+01, -5.29167865e+02,  1.61404939e+02,\n",
      "         8.01330348e+01, -4.14583769e+01,  3.80782796e+02,\n",
      "         7.92267100e+01, -1.65519210e+02, -6.69340035e+02,\n",
      "        -3.57842683e+02],\n",
      "       [-1.95968758e+02,  2.72743710e+02, -5.02413699e+01,\n",
      "        -5.82162406e+02, -1.36910768e+02, -2.15885447e+02,\n",
      "        -5.59722994e+01, -2.65005600e+01,  7.59432256e+01,\n",
      "         6.79241667e+01],\n",
      "       [ 1.88134768e+01, -1.23372206e+02,  2.53286968e+02,\n",
      "         2.80498875e+02,  5.68064487e+01,  3.34382660e+02,\n",
      "         1.51905875e+02,  2.65675548e+01,  3.37229075e+02,\n",
      "         1.13125785e+02],\n",
      "       [ 5.84930013e+02, -1.28246895e+02, -1.17915309e+02,\n",
      "        -2.77464932e+02, -2.36022664e+01,  3.75657945e+02,\n",
      "        -4.49626013e+02, -1.79213936e+02, -3.32293565e+02,\n",
      "        -2.65927330e+02],\n",
      "       [ 1.79766698e+02, -3.50704955e+02, -1.12606327e+02,\n",
      "         6.07727109e+01,  4.42390763e+02,  1.30220833e+02,\n",
      "         2.49596027e+02,  2.87024838e+02,  4.41263622e+01,\n",
      "         6.09948581e+02],\n",
      "       [-2.59435935e+02,  1.78385762e+02, -3.71098291e+01,\n",
      "         1.03038724e+02,  1.19257623e+01, -1.32126837e+02,\n",
      "        -2.09225612e+02, -1.90919283e+02, -8.28820055e+01,\n",
      "        -3.43639230e+02]]), array([[  81.91824809],\n",
      "       [  73.25731203],\n",
      "       [ 252.93588173],\n",
      "       [ 391.61894785],\n",
      "       [ 136.37009534],\n",
      "       [  47.81785403],\n",
      "       [1197.23231979],\n",
      "       [ 460.898243  ],\n",
      "       [ 723.73134784],\n",
      "       [  84.13360113]])]\n",
      "[array([ -202.56560274,   621.94076798,   880.14838545, -1074.64749323,\n",
      "         805.05114427,   411.62940093, -1203.7245418 ,  -518.04528168,\n",
      "       -1506.93576264,  -547.49989424]), array([364.46163302])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "#let's build a NN with 10 nodes in the only hidden layer\n",
    "\n",
    "#let's define the model\n",
    "mlp_1h10n = MLPRegressor(hidden_layer_sizes=(10, ), solver='lbfgs', random_state=numero_di_matricola)\n",
    "#after warning shows up\n",
    "#mlp_1h10n = MLPRegressor(hidden_layer_sizes=(10, ), solver='lbfgs', random_state=numero_di_matricola, max_iter=2000)\n",
    "\n",
    "#let's learn the model on training data\n",
    "mlp_1h10n.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"1 - coefficient of determination on training data:\"+str(1 - mlp_1h10n.score(Xtrain_scaled,Ytrain)))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"1 - coefficient of determination on validation data:\"+str(1 - mlp_1h10n.score(Xval_scaled,Yval)))\n",
    "\n",
    "#let's print the coefficients of the model for the input nodes (but not the bias)\n",
    "print(mlp_1h10n.coefs_)\n",
    "\n",
    "#let's print the coefficient for the bias (i.e., the bias)\n",
    "print(mlp_1h10n.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a NN with 100 nodes in the only hidden layer. Note that this is the default!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - coefficient of determination on training data:0.0056883091996713375\n",
      "1 - coefficient of determination on validation data:0.46052974578925765\n",
      "[array([[ 115.24281737, -163.49646818,   54.80382447, ..., -201.87755222,\n",
      "         282.54617959, -141.82450431],\n",
      "       [  29.90365796,   -7.43168755,  123.51123257, ...,  -35.54934659,\n",
      "         -16.1330471 ,  156.70589859],\n",
      "       [ -19.64638801,  -92.7932688 ,   98.45478367, ...,  104.37181717,\n",
      "         188.76251012,  -40.07747518],\n",
      "       ...,\n",
      "       [ 205.35207294,  -88.36422392,   68.28708344, ..., -413.00848478,\n",
      "         165.94885302,  -63.71508193],\n",
      "       [-166.02566344,  117.65152734,  188.33233584, ..., -133.85371867,\n",
      "         -95.39810204,   -9.92049798],\n",
      "       [ 124.1821239 , -179.28557411,   27.65916067, ...,  -61.02674385,\n",
      "         132.50713202,   71.47444781]]), array([[ 344.88128192],\n",
      "       [ 294.86088992],\n",
      "       [-206.68276448],\n",
      "       [-384.44957602],\n",
      "       [ 334.24215541],\n",
      "       [ 380.00348726],\n",
      "       [ 275.80091613],\n",
      "       [ 467.66598528],\n",
      "       [-416.48161402],\n",
      "       [-374.26174847],\n",
      "       [ 339.4957314 ],\n",
      "       [-413.00642782],\n",
      "       [ 370.52758562],\n",
      "       [ 255.85634257],\n",
      "       [-354.75638699],\n",
      "       [ 418.11945268],\n",
      "       [ 616.14813308],\n",
      "       [-570.60571135],\n",
      "       [-397.30691369],\n",
      "       [ 253.51361101],\n",
      "       [-384.28333104],\n",
      "       [ 320.07499654],\n",
      "       [ 322.01796268],\n",
      "       [ 538.59811997],\n",
      "       [ 439.50451064],\n",
      "       [-436.44027789],\n",
      "       [ 402.61394375],\n",
      "       [-579.90304914],\n",
      "       [ 339.82555835],\n",
      "       [ 351.44702869],\n",
      "       [ 440.52441676],\n",
      "       [-715.26574945],\n",
      "       [ 421.00312787],\n",
      "       [ 794.22442782],\n",
      "       [-806.11752503],\n",
      "       [ 384.62826651],\n",
      "       [ 449.67736788],\n",
      "       [-502.4967351 ],\n",
      "       [ 300.98394899],\n",
      "       [-489.81558269],\n",
      "       [ 397.10479004],\n",
      "       [ 281.67440683],\n",
      "       [ 840.25020328],\n",
      "       [ 417.48734514],\n",
      "       [ 370.41256237],\n",
      "       [-465.69238494],\n",
      "       [-361.04046159],\n",
      "       [-416.09218513],\n",
      "       [ -27.58811153],\n",
      "       [-418.953928  ],\n",
      "       [1070.22262858],\n",
      "       [ 263.36004997],\n",
      "       [ 339.36918049],\n",
      "       [ 262.34383849],\n",
      "       [ 326.71500565],\n",
      "       [-510.40528819],\n",
      "       [-397.4732205 ],\n",
      "       [ 363.22230481],\n",
      "       [ 414.15169447],\n",
      "       [ 380.38561932],\n",
      "       [ 465.89402142],\n",
      "       [ 424.33225416],\n",
      "       [-550.20791117],\n",
      "       [-327.8345524 ],\n",
      "       [ 430.21857165],\n",
      "       [-353.86247625],\n",
      "       [ 498.99106592],\n",
      "       [-465.23830066],\n",
      "       [-380.94755255],\n",
      "       [-480.97713096],\n",
      "       [ 875.56506593],\n",
      "       [-321.17101201],\n",
      "       [-550.42401478],\n",
      "       [ 469.3243503 ],\n",
      "       [-609.98906168],\n",
      "       [ 349.51501903],\n",
      "       [ 387.61623555],\n",
      "       [ 446.52739661],\n",
      "       [-482.80607608],\n",
      "       [ 397.94860352],\n",
      "       [ 455.72507626],\n",
      "       [ 413.49334174],\n",
      "       [ 393.93186597],\n",
      "       [ 378.75057497],\n",
      "       [ 464.05239763],\n",
      "       [-508.85717061],\n",
      "       [-480.32016325],\n",
      "       [ 423.22832667],\n",
      "       [-447.64613139],\n",
      "       [-570.95258656],\n",
      "       [ 351.92047685],\n",
      "       [ 418.81578964],\n",
      "       [ 657.74860441],\n",
      "       [ 286.27328775],\n",
      "       [-637.08731044],\n",
      "       [ 587.68216959],\n",
      "       [ -24.6842384 ],\n",
      "       [-560.65242307],\n",
      "       [-283.89026911],\n",
      "       [ 319.98615605]])]\n",
      "[array([ 3.51331651e+02, -9.99066956e+00, -4.63194949e+01, -1.71223120e+02,\n",
      "        1.62214668e+02,  2.03879786e+02,  2.83658461e+01, -5.52435467e+02,\n",
      "        1.01763717e+02,  2.31192771e+01, -2.40823705e+02, -1.88019788e+02,\n",
      "        1.83120783e+02,  1.01130566e+02, -3.13559887e+02,  4.56252426e+01,\n",
      "       -8.65311403e+02, -4.51059417e+02,  8.37881748e+00,  3.80185276e+02,\n",
      "        2.26794111e+02, -3.13269238e+02,  3.87634067e+02,  3.88150284e+02,\n",
      "        2.53777181e+02, -6.28685963e+02, -1.41903423e+02,  3.67428046e+02,\n",
      "        5.22325675e-01, -4.92808523e+02,  3.03013193e+02, -3.60864796e+02,\n",
      "       -1.40485459e+02, -8.66779855e+02, -7.93066320e+02,  2.10979761e+02,\n",
      "        3.45971616e+02,  1.54870741e+02,  1.61999357e+02,  1.05438168e+02,\n",
      "       -1.95738438e+02, -1.00767983e+02, -1.09186513e+03,  1.25152142e+02,\n",
      "        8.06692217e+01, -1.77384349e+02,  8.18446644e+00,  4.26793984e+02,\n",
      "       -1.57374273e+02,  2.63810650e+02, -1.37937620e+03,  1.08260915e+02,\n",
      "       -5.43283530e+01,  1.93564530e+02, -2.57508866e+02,  2.41887117e+02,\n",
      "        1.20672702e+02,  1.90986651e+01, -2.71577094e+02, -2.03109009e+02,\n",
      "        4.19084707e+02, -7.47403462e+01, -2.34099853e+02, -1.94839184e+02,\n",
      "       -3.60840050e+02, -8.78610169e+01, -1.97522027e+02, -1.71890801e+02,\n",
      "        2.68664119e+01, -1.86696458e+02, -7.88110658e+02,  1.92580516e+02,\n",
      "       -1.18154768e+02, -3.60954507e+02,  4.75856825e+02,  2.34321522e+02,\n",
      "       -3.88653185e+01, -4.83555484e+02, -1.95559771e+02, -2.40639923e+02,\n",
      "       -1.17960438e+02, -4.61578589e+02, -5.87703160e+02,  4.66373061e+02,\n",
      "       -2.24774843e+02,  4.58285581e+02,  3.34877380e+02, -4.53658250e+02,\n",
      "       -8.31149488e+01,  4.72233231e+02,  2.73037823e+02,  5.82425586e+02,\n",
      "       -7.37450714e+02, -2.55720624e+02, -4.24580938e+02, -6.85703733e+02,\n",
      "       -1.24969939e+02, -3.05605469e+02, -3.95327616e+02,  5.71228562e+02]), array([327.4800684])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "#let's build a NN with 100 nodes in the only hidden layer\n",
    "\n",
    "#let's define the model\n",
    "#mlp_1h100n = MLPRegressor( solver='lbfgs', random_state=numero_di_matricola)\n",
    "#after warning shows up\n",
    "mlp_1h100n = MLPRegressor( solver='lbfgs', random_state=numero_di_matricola, max_iter=2000)\n",
    "\n",
    "#let's learn the model on training data\n",
    "mlp_1h100n.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"1 - coefficient of determination on training data:\"+str(1 - mlp_1h100n.score(Xtrain_scaled,Ytrain)))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"1 - coefficient of determination on validation data:\"+str(1 - mlp_1h100n.score(Xval_scaled,Yval)))\n",
    "\n",
    "#let's print the coefficients of the model for the input nodes (but not the bias)\n",
    "print(mlp_1h100n.coefs_)\n",
    "\n",
    "#let's print the coefficient for the bias (i.e., the bias)\n",
    "print(mlp_1h100n.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try 2 layers, 1 node each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - coefficient of determination on training data:0.23948760580621697\n",
      "1 - coefficient of determination on validation data:0.2732843765477735\n",
      "[array([[ -30.57061812],\n",
      "       [  86.99389466],\n",
      "       [ 145.03065276],\n",
      "       [ -55.23024929],\n",
      "       [   5.3097072 ],\n",
      "       [ 185.60710792],\n",
      "       [  67.66273043],\n",
      "       [  62.20863821],\n",
      "       [ 287.43558086],\n",
      "       [ 139.33503606],\n",
      "       [  41.07668768],\n",
      "       [-174.3041627 ],\n",
      "       [  10.09706642],\n",
      "       [-129.0473273 ],\n",
      "       [ 266.30824181],\n",
      "       [-196.26759294],\n",
      "       [ 100.45437696],\n",
      "       [ -53.8221099 ]]), array([[1.27078642]]), array([[439.48822783]])]\n",
      "[array([151.96459835]), array([746.54275373]), array([471.66676482])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "#let's build a NN with 2 hidden layers, 1 node each\n",
    "\n",
    "#let's define the model\n",
    "mlp_2h1n1n = MLPRegressor(hidden_layer_sizes=(1,1 ), solver='lbfgs', random_state=numero_di_matricola)\n",
    "#after warning shows up\n",
    "#mlp_2h2n2n = MLPRegressor(hidden_layer_sizes=(1,1 ), solver='lbfgs', random_state=numero_di_matricola, max_iter=2000)\n",
    "\n",
    "#let's learn the model on training data\n",
    "mlp_2h1n1n.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"1 - coefficient of determination on training data:\"+str(1 - mlp_2h1n1n.score(Xtrain_scaled,Ytrain)))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"1 - coefficient of determination on validation data:\"+str(1 - mlp_2h1n1n.score(Xval_scaled,Yval)))\n",
    "\n",
    "#let's print the coefficients of the model for the input nodes (but not the bias)\n",
    "print(mlp_2h1n1n.coefs_)\n",
    "\n",
    "#let's print the coefficient for the bias (i.e., the bias)\n",
    "print(mlp_2h1n1n.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try 2 layers, 2 nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - coefficient of determination on training data:0.18976088361805876\n",
      "1 - coefficient of determination on validation data:0.22445179393159198\n",
      "[array([[-2.09847647e-01, -1.00378950e+02],\n",
      "       [ 2.76565516e+00, -2.33486511e+03],\n",
      "       [ 1.24024123e+00, -1.60201752e+02],\n",
      "       [-2.34353052e+00,  2.19417176e+03],\n",
      "       [-5.29191722e-01,  4.99166428e+02],\n",
      "       [ 2.56784045e+00, -1.79908016e+03],\n",
      "       [ 9.10299258e-01, -3.07582263e+02],\n",
      "       [ 1.07099692e+00, -7.10232561e+02],\n",
      "       [ 6.24547191e+00, -4.27088540e+03],\n",
      "       [ 1.55151072e+00, -3.96757745e+02],\n",
      "       [ 8.40950202e-02,  3.97463944e+02],\n",
      "       [-5.45313524e+00,  4.31721166e+03],\n",
      "       [-4.96706933e-01,  7.86887624e+02],\n",
      "       [-3.99578176e+00,  3.10147521e+03],\n",
      "       [ 4.35815829e+00, -2.24686801e+03],\n",
      "       [-3.74304025e+00,  2.89611987e+03],\n",
      "       [ 1.54900445e+00, -7.88138714e+02],\n",
      "       [-1.28754704e+00,  9.50207277e+02]]), array([[-1.21884347e+02,  5.07830577e+01],\n",
      "       [-9.45555318e+02,  6.12357052e-02]]), array([[643.13976289],\n",
      "       [977.04590659]])]\n",
      "[array([3436.98680906, 8106.6913928 ]), array([   -534.12294399, -174536.06268151]), array([-38.10973966])]\n"
     ]
    }
   ],
   "source": [
    "#let's build a NN with 2 layers, 2 nodes each\n",
    "\n",
    "#let's define the model\n",
    "#mlp_2h2n2n = MLPRegressor(hidden_layer_sizes=(2,2 ), solver='lbfgs', random_state=numero_di_matricola)\n",
    "#after warning shows up\n",
    "mlp_2h2n2n = MLPRegressor(hidden_layer_sizes=(2,2 ), solver='lbfgs', random_state=numero_di_matricola, max_iter=2000)\n",
    "\n",
    "#let's learn the model on training data\n",
    "mlp_2h2n2n.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"1 - coefficient of determination on training data:\"+str(1 - mlp_2h2n2n.score(Xtrain_scaled,Ytrain)))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"1 - coefficient of determination on validation data:\"+str(1 - mlp_2h2n2n.score(Xval_scaled,Yval)))\n",
    "\n",
    "#let's print the coefficients of the model for the input nodes (but not the bias)\n",
    "print(mlp_2h2n2n.coefs_)\n",
    "\n",
    "#let's print the coefficient for the bias (i.e., the bias)\n",
    "print(mlp_2h2n2n.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try 2 layers, 10 nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - coefficient of determination on training data:0.06621289533351216\n",
      "1 - coefficient of determination on validation data:0.29563024555643835\n",
      "[array([[ 8.93364368e+00,  8.51572410e+00,  9.82393523e+00,\n",
      "         1.81464247e-01, -1.38164306e+01, -2.97021621e+01,\n",
      "        -7.79145262e+00, -1.92904783e+01, -7.71390731e+00,\n",
      "         1.70251100e+01],\n",
      "       [ 1.45875600e+00,  3.23883045e+01,  2.46386803e+01,\n",
      "         1.61915395e+01, -1.56902346e+01,  4.73775575e+01,\n",
      "        -7.87426180e+00,  7.86043046e+00, -1.89158837e+01,\n",
      "        -1.08519513e+01],\n",
      "       [-2.65718884e+01,  1.93518607e+01,  1.24684787e+01,\n",
      "        -8.19153452e+00, -1.08397977e+01,  1.17885066e+01,\n",
      "         7.50560894e+00,  3.43338929e+01, -4.03207212e+01,\n",
      "        -4.95395389e+00],\n",
      "       [-6.15714741e+00, -7.39442466e-01,  1.34584339e+01,\n",
      "        -2.05738045e+01, -2.20306536e+01, -5.73604382e+00,\n",
      "        -7.74797202e+00, -6.22712459e+00,  5.48816493e+00,\n",
      "        -5.44847653e-01],\n",
      "       [-3.36402610e+01,  2.60476761e+01, -2.07823903e+01,\n",
      "        -9.31026930e+00,  1.93613207e+01, -5.72380653e+01,\n",
      "         1.09261151e+01, -3.57045427e+01,  1.69465835e+01,\n",
      "        -8.07902364e+01],\n",
      "       [-3.23809028e+01,  1.30510084e+01,  1.05175216e+01,\n",
      "        -4.24867895e+01, -4.70830063e+01,  3.57945302e+01,\n",
      "        -2.65173402e+01, -1.44881533e+01, -6.16854052e+01,\n",
      "         3.61317875e+01],\n",
      "       [-2.34768992e+01,  4.27507756e+01,  2.27180184e+01,\n",
      "        -2.14559436e+01, -6.90084228e+00, -1.81674092e+01,\n",
      "        -3.09985976e+01,  5.67182363e+01, -1.53965747e+01,\n",
      "        -6.50971986e+00],\n",
      "       [-1.06414831e+01,  2.20325965e+01,  1.41582142e+01,\n",
      "        -8.98146034e+00,  3.10910731e+01, -7.23830364e+01,\n",
      "        -1.35587091e+01,  6.64454836e+01,  2.00402371e+01,\n",
      "         4.19932311e-01],\n",
      "       [ 4.60016491e-02,  3.77350624e+01,  4.59858014e+01,\n",
      "        -4.70415948e-01,  1.03282509e+01,  3.49307830e+01,\n",
      "        -1.82511012e+01,  4.06292066e+01, -3.69115467e+01,\n",
      "         3.02132909e+01],\n",
      "       [-9.10709716e+00,  2.36929231e+01,  1.96306482e+01,\n",
      "        -7.46945121e+00, -1.26124279e+01,  1.72232455e+01,\n",
      "         2.05785407e+00,  4.27218740e+01, -4.52926000e+01,\n",
      "        -9.26677921e+00],\n",
      "       [-3.84958832e+01, -4.02257059e+00, -9.83170512e+00,\n",
      "        -3.34333373e+00,  5.24102942e-01, -8.52251455e+00,\n",
      "         1.24260219e+01, -6.83042720e+00,  7.49169314e-01,\n",
      "         6.76677386e+00],\n",
      "       [-1.91531296e+01,  2.91639601e+01,  3.17077102e+00,\n",
      "        -7.66092190e+00, -9.30652630e+01,  1.19327077e+02,\n",
      "         1.02030530e+01, -1.61125942e+01, -4.23763153e+01,\n",
      "        -1.32909881e+02],\n",
      "       [-1.33592731e+01, -3.63950101e+01, -3.14690950e+00,\n",
      "        -1.40374702e+01,  9.58726061e+01,  1.76636381e+01,\n",
      "        -7.71401262e+01, -3.53803269e+01,  3.44397838e+01,\n",
      "        -8.84786427e+01],\n",
      "       [-7.16542796e+01, -1.15351901e+02, -8.03996783e+00,\n",
      "         1.21943582e+01,  2.12519669e+01,  2.90332939e+01,\n",
      "         6.39025433e+00, -2.07553726e+01,  6.79288286e+00,\n",
      "        -3.22061703e+01],\n",
      "       [-3.31509496e+01,  3.31052185e+01,  3.63815325e+01,\n",
      "        -1.95417458e+02,  4.43703279e+01, -5.81360185e+00,\n",
      "        -1.02340281e+02,  5.52692736e+01,  9.59461961e+01,\n",
      "         7.63461909e+01],\n",
      "       [ 1.46998892e+01, -6.52951315e+01,  2.24414947e+01,\n",
      "         1.23730412e+01, -5.64107501e+01, -1.00343349e+01,\n",
      "        -2.63896454e+01, -2.68854656e+00, -1.84697932e+01,\n",
      "        -1.14475379e+01],\n",
      "       [ 1.55373804e+01, -1.79540116e+00, -9.74387847e+00,\n",
      "        -1.07047522e+01,  6.14006848e+01, -4.31233097e+01,\n",
      "         1.26850971e+00,  4.54976696e+01,  1.39760570e+01,\n",
      "         4.86453979e+01],\n",
      "       [-8.09817261e+00,  3.36648914e+00, -9.48151073e+00,\n",
      "        -4.74517886e+00,  1.53657420e+00, -3.94147930e+01,\n",
      "         2.91407098e+00,  2.48645041e+00, -4.88429960e+00,\n",
      "        -2.60934116e+01]]), array([[-8.30227871e-01, -4.38610215e-01,  1.65631101e+01,\n",
      "        -3.95337698e+00, -9.28324578e+00, -5.52794438e-01,\n",
      "        -5.38005858e-01, -1.74569058e+00,  2.13669705e+01,\n",
      "        -5.53946248e+00],\n",
      "       [ 1.35491005e+01,  1.06427366e+01, -2.43421746e+00,\n",
      "         5.06274755e+00, -2.80872383e+00, -1.37548810e+00,\n",
      "        -2.22157716e+00, -1.09988422e+01,  4.43705441e+01,\n",
      "        -8.89028867e+00],\n",
      "       [ 2.20810832e+01,  6.68600564e+01,  1.45615518e+01,\n",
      "         2.02889150e+00, -4.57953172e+00, -7.94304046e-01,\n",
      "        -5.63756233e-01, -6.08737251e+00, -3.50345642e+01,\n",
      "        -4.97559841e+00],\n",
      "       [-1.36656995e+01, -1.04144052e+01, -5.28567010e+01,\n",
      "        -3.49774643e+01, -1.99413269e+00, -1.54291075e-01,\n",
      "        -4.63055755e-01, -4.19553873e+00, -1.11463592e+02,\n",
      "        -3.56394175e+00],\n",
      "       [ 8.16297674e+00,  3.47047911e+01, -2.40179683e+00,\n",
      "         1.12965306e+01, -7.17117368e+00, -6.17007634e-01,\n",
      "        -5.33643193e-01, -2.56755842e+00,  2.79127298e+01,\n",
      "        -4.40368068e+00],\n",
      "       [ 9.86065944e-01,  1.70998300e+00, -8.53983268e+00,\n",
      "         4.44244300e+00, -4.91850025e+00, -6.11018814e-01,\n",
      "        -6.08662020e-01, -5.81593652e+00,  2.95872907e+01,\n",
      "        -4.86867032e+00],\n",
      "       [ 1.68113873e+01,  3.86360149e+01,  4.13255094e+01,\n",
      "         2.23516674e+01, -3.70511244e+00, -1.47123359e-01,\n",
      "        -6.63789764e-02, -1.89558159e+00,  2.30386509e+01,\n",
      "        -2.66036824e+00],\n",
      "       [ 6.52915906e+00,  1.08298558e+01, -1.84209463e+00,\n",
      "         6.15052952e+00, -5.39425209e+00, -6.70604711e-01,\n",
      "        -1.44926137e-01, -3.69052997e+00,  7.23472948e-01,\n",
      "        -4.16198633e+00],\n",
      "       [-6.20693087e+00, -1.24669439e+01,  3.78501249e+00,\n",
      "        -1.72202999e+01, -7.18656855e+00, -5.92790132e-01,\n",
      "        -3.69126143e-01, -3.77829522e+00, -8.90438515e+01,\n",
      "        -4.30645705e+00],\n",
      "       [ 1.26474612e+00, -1.06780416e+01, -4.79144905e+00,\n",
      "         1.34919310e+01, -6.93064358e+00, -1.18522346e+00,\n",
      "        -1.10352544e+00, -1.04428429e+01,  2.32713129e+01,\n",
      "        -8.74607801e+00]]), array([[  2.01142656],\n",
      "       [ 19.19517947],\n",
      "       [ 30.33202831],\n",
      "       [ 27.22413387],\n",
      "       [ 12.30666638],\n",
      "       [ 22.64153577],\n",
      "       [  0.76180639],\n",
      "       [ 11.94735352],\n",
      "       [119.60825803],\n",
      "       [ 38.79435174]])]\n",
      "[array([  81.03678741, -214.61126543,  159.29559397,   70.33605541,\n",
      "         37.33155936,  -69.0410488 ,  127.67699853,  -27.65845133,\n",
      "          1.20333732,  -86.42833473]), array([ 10.71170553,  20.02079089,  10.50403931,   1.77324985,\n",
      "       -12.62950537,  -1.93333659,  -0.8961322 ,  -7.91433201,\n",
      "         3.87416755, -10.53482549]), array([42.51370633])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "#let's build a NN with 2 layers, 10 nodes each\n",
    "\n",
    "#let's define the model\n",
    "mlp_2h10n10n = MLPRegressor(hidden_layer_sizes=(10,10 ), solver='lbfgs', random_state=numero_di_matricola)\n",
    "#after warning shows up\n",
    "#mlp_2h10n10n = MLPRegressor(hidden_layer_sizes=(10,10 ), solver='lbfgs', random_state=numero_di_matricola, max_iter=2000)\n",
    "\n",
    "#let's learn the model on training data\n",
    "mlp_2h10n10n.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"1 - coefficient of determination on training data:\"+str(1 - mlp_2h10n10n.score(Xtrain_scaled,Ytrain)))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"1 - coefficient of determination on validation data:\"+str(1 - mlp_2h10n10n.score(Xval_scaled,Yval)))\n",
    "\n",
    "#let's print the coefficients of the model for the input nodes (but not the bias)\n",
    "print(mlp_2h10n10n.coefs_)\n",
    "\n",
    "#let's print the coefficient for the bias (i.e., the bias)\n",
    "print(mlp_2h10n10n.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try 2 layers, 100 nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - coefficient of determination on training data:0.0014192223848940033\n",
      "1 - coefficient of determination on validation data:0.5532883468853576\n",
      "[array([[ 12.23512105,   1.45005128,  10.11808758, ...,  -6.92494762,\n",
      "        -19.53186983,  -3.04785637],\n",
      "       [-12.8783077 ,   1.6175057 ,   4.68008205, ...,  -3.14387511,\n",
      "         -2.39113725, -10.65235857],\n",
      "       [ -7.07862566,  -0.37290407,  13.50941469, ...,  -4.29072353,\n",
      "         -6.46563699,  -5.27562214],\n",
      "       ...,\n",
      "       [ 13.20141055,  -2.70029797,  15.85890151, ...,  29.47150452,\n",
      "        -16.01433   ,  15.55480683],\n",
      "       [ -2.31412466,  -1.49628324, -20.06121675, ...,  -1.63826517,\n",
      "         31.82441427,  -3.74573121],\n",
      "       [-25.44914422,  -3.27917396,   8.13858746, ...,   8.36406754,\n",
      "         -3.50814778,  -4.06361816]]), array([[ -2.43129836,  -3.5152822 ,  -1.03968664, ...,   1.27226419,\n",
      "         -5.61351262, -10.02258159],\n",
      "       [ -2.18649253,   0.18057474,  -0.02471565, ...,   0.07921554,\n",
      "          0.36197048,   0.53452876],\n",
      "       [ -1.10636473,  -3.93540288,  -0.47432902, ...,  -9.65638008,\n",
      "          3.0027647 ,   0.62703566],\n",
      "       ...,\n",
      "       [ -3.30219977,  -5.84970623,  -0.73294432, ...,  -8.53120668,\n",
      "          6.94465496,   5.53144628],\n",
      "       [ -1.8443245 ,  -5.4637787 ,  -0.2401023 , ...,   3.84832996,\n",
      "        -12.73783269,   5.79127223],\n",
      "       [ -2.98085405,   1.32200411,  -0.50948647, ...,  -6.3800238 ,\n",
      "         -6.07407013,   9.26978729]]), array([[ 7.97547284e+00],\n",
      "       [ 4.58184071e+01],\n",
      "       [ 1.73426070e+00],\n",
      "       [ 2.04698411e+01],\n",
      "       [ 4.63115982e+01],\n",
      "       [ 5.42711390e-01],\n",
      "       [ 1.01597323e+01],\n",
      "       [ 3.49905054e+00],\n",
      "       [ 2.29875498e+00],\n",
      "       [ 1.75011880e+01],\n",
      "       [ 2.94757294e+01],\n",
      "       [ 1.08513285e+01],\n",
      "       [ 5.06869827e+01],\n",
      "       [ 1.37766523e+00],\n",
      "       [ 1.08448193e+02],\n",
      "       [ 2.40480854e+00],\n",
      "       [ 3.74118454e+01],\n",
      "       [ 7.26641527e+00],\n",
      "       [ 3.97131534e+01],\n",
      "       [ 4.83377066e+01],\n",
      "       [ 1.14137889e+01],\n",
      "       [ 9.20803388e+00],\n",
      "       [-3.21886667e+01],\n",
      "       [ 1.76719682e+01],\n",
      "       [ 8.80297358e-01],\n",
      "       [ 6.86791887e+01],\n",
      "       [ 2.34892113e+00],\n",
      "       [ 9.85595740e+00],\n",
      "       [ 2.66546671e+01],\n",
      "       [ 7.72024146e+00],\n",
      "       [ 6.41434276e+01],\n",
      "       [ 4.64894904e+01],\n",
      "       [ 8.88944489e-01],\n",
      "       [-4.88197591e+01],\n",
      "       [ 5.94800910e+00],\n",
      "       [ 2.25054992e+00],\n",
      "       [ 6.28021934e+01],\n",
      "       [-1.08307705e+00],\n",
      "       [ 4.74288230e+00],\n",
      "       [ 5.28845940e+00],\n",
      "       [ 2.54567472e+00],\n",
      "       [-2.88752764e+00],\n",
      "       [-7.28572622e+00],\n",
      "       [ 1.44800104e+01],\n",
      "       [ 6.20888887e+01],\n",
      "       [ 5.44021261e+00],\n",
      "       [ 1.33875789e-01],\n",
      "       [ 1.95384303e+01],\n",
      "       [ 6.75264661e-01],\n",
      "       [ 7.22181329e+01],\n",
      "       [ 1.13848164e+01],\n",
      "       [ 1.75385514e+00],\n",
      "       [ 1.48617149e+01],\n",
      "       [ 8.69727498e+00],\n",
      "       [ 1.63677466e-01],\n",
      "       [ 4.34876050e+00],\n",
      "       [-1.47721293e+01],\n",
      "       [-3.38532287e+01],\n",
      "       [ 1.88361337e+00],\n",
      "       [ 1.08363864e+01],\n",
      "       [-4.14294543e+01],\n",
      "       [ 3.23185749e+01],\n",
      "       [ 1.47538034e+00],\n",
      "       [ 3.85130778e+00],\n",
      "       [-1.28528814e+01],\n",
      "       [ 4.23947393e+01],\n",
      "       [ 6.47363869e-01],\n",
      "       [-8.66271443e+00],\n",
      "       [ 5.53362769e+01],\n",
      "       [ 1.83003726e+00],\n",
      "       [ 3.78066970e+01],\n",
      "       [ 1.60963203e+01],\n",
      "       [ 4.19173060e+01],\n",
      "       [ 7.22674866e+01],\n",
      "       [ 1.66332426e+00],\n",
      "       [-3.63368240e+00],\n",
      "       [-6.16499908e+00],\n",
      "       [ 2.37584495e+01],\n",
      "       [-1.84428824e+01],\n",
      "       [ 9.37926604e+01],\n",
      "       [ 9.68687178e+00],\n",
      "       [ 9.20257642e+01],\n",
      "       [ 1.67971484e+00],\n",
      "       [ 4.26491772e+01],\n",
      "       [-1.62894010e+01],\n",
      "       [ 1.84366125e+01],\n",
      "       [ 1.45914618e+01],\n",
      "       [ 5.33339227e+00],\n",
      "       [ 3.59225266e+01],\n",
      "       [ 6.10291478e+01],\n",
      "       [ 2.32635951e+01],\n",
      "       [-2.05895439e+00],\n",
      "       [ 1.26598800e+02],\n",
      "       [-6.85508820e-02],\n",
      "       [ 2.36850657e+01],\n",
      "       [ 2.81685925e+00],\n",
      "       [ 3.88095713e+00],\n",
      "       [ 4.00110084e+01],\n",
      "       [ 4.75088495e+01],\n",
      "       [ 3.22972170e+01]])]\n",
      "[array([ -1.71057945, -17.25052391, -28.1431645 ,  45.66785548,\n",
      "        39.78070706,  68.25776174,  -2.65458071, -18.47819952,\n",
      "        43.23716611, -13.28193928, -22.85896004, -51.6053184 ,\n",
      "        12.3233773 ,  10.77922096,  27.24769792, -49.77751997,\n",
      "        33.00459628,  -4.36832338,  -9.98594774, -68.63977361,\n",
      "       -12.54182619,  19.62724389,  39.72601626,  15.0425725 ,\n",
      "         7.48773751, -39.49148336,  35.33966139, -85.23074346,\n",
      "        -9.90836444, -17.78131809, -53.79275937,  -1.44708137,\n",
      "       -13.1735948 ,  11.17279248, -83.68880617,  -3.69036298,\n",
      "       -17.74161948,   5.11078087,  -2.02243906, -19.36501329,\n",
      "        33.02468934,  35.40711485,  60.69578658,  -4.81463162,\n",
      "         9.96619087,  10.55831336, -13.65737899, -72.19366069,\n",
      "       -23.68606587,   3.35055912,  31.70352535, -24.74717459,\n",
      "        21.59039391, -55.5341865 , -33.58942329,  29.44894954,\n",
      "       -12.19870968,   6.64195215,  -0.28533531,  10.86353746,\n",
      "        21.931009  ,  53.9872836 ,  72.40277318,  56.85679296,\n",
      "       -22.85240925, -46.57379213, -27.32976217, -22.80464293,\n",
      "       -29.23509148,  26.63793305,  65.50738188,   4.14013339,\n",
      "       -40.92002762,   2.91168403, -30.84916638,  30.6428476 ,\n",
      "       -41.62302334,  22.36628966, -32.89610998, -14.75782211,\n",
      "        23.70459447,  15.78848638, -45.74109724,  72.70688357,\n",
      "        14.28848518,  22.20140765,   0.61473788, -68.94936645,\n",
      "        34.56449296,  -8.99277894,  36.75839849,  28.71297126,\n",
      "        -7.09610908, -23.89777764,   4.48605783,  21.89060007,\n",
      "        16.94162851,   4.3080114 ,  -4.04758055, -29.10170263]), array([ -8.07106165,   0.73842209,  -2.51242883,  -5.80422965,\n",
      "         3.56918962,  -1.75297515,  -2.39224688,  -2.94384646,\n",
      "         0.17928581,  -6.34555109, -12.68789235,   6.87405308,\n",
      "         0.5981051 ,  -0.72685366,   6.08367509,  -2.01985707,\n",
      "         5.58250691,  -1.35037211, -12.90288174,   8.9366641 ,\n",
      "        -0.79366294,  -9.60166062,   8.89357417,  -4.53964271,\n",
      "        -0.99749929,   4.43664268,  -2.05554581,  -6.50508546,\n",
      "         2.03707005,  -4.21773716,  -0.07888882,   2.02690976,\n",
      "        -1.07195651,   0.9233371 ,  10.16066303,  -0.36896387,\n",
      "         2.94737424,   4.51340002,  -1.33135871,   1.54104403,\n",
      "        -1.85366792,   3.2108484 ,   2.85564206,   7.58646969,\n",
      "         1.84193874,  -2.80880367,   0.1215428 ,  -5.97125139,\n",
      "        -0.39388767,   5.76333313,  -7.17529022,  -0.95368045,\n",
      "        -1.21526952,  -3.93229466,   7.66402399,  -1.40995264,\n",
      "         6.08794914,   5.80144052,  -2.79580936,  -6.92892308,\n",
      "        13.13567507,  -8.48344983,  -0.47546154,  -1.9352627 ,\n",
      "         8.96744353,   5.92552632,  -0.37512357,   1.3398445 ,\n",
      "         4.35137733,   3.70230653,   1.58316441,  -1.03730632,\n",
      "         2.12039695,   1.835549  ,  -0.93852671,   0.73766841,\n",
      "         1.27015126, -11.39133458,   4.45537845,   1.54544534,\n",
      "        -1.30624348,   6.53718921,  -2.54133317,  -9.69474855,\n",
      "         8.53290292,   1.51191062,  -7.70226618,  -1.52702992,\n",
      "       -13.39398122,   6.53524589,  -6.16933183,   6.36478902,\n",
      "         9.75851061,  -0.01949496, -12.20621767,  -3.97639217,\n",
      "        -4.69927196,   0.04437408,   2.51977483,   8.9806471 ]), array([63.367576])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "#let's build a NN with 2 layers, 100 nodes each\n",
    "\n",
    "#let's define the model\n",
    "#mlp_2h100n100n = MLPRegressor(hidden_layer_sizes=(100,100 ), solver='lbfgs', random_state=numero_di_matricola)\n",
    "#after warning shows up\n",
    "mlp_2h100n100n = MLPRegressor(hidden_layer_sizes=(100,100 ), solver='lbfgs', random_state=numero_di_matricola, max_iter=2000)\n",
    "\n",
    "#let's learn the model on training data\n",
    "mlp_2h100n100n.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"1 - coefficient of determination on training data:\"+str(1 - mlp_2h100n100n.score(Xtrain_scaled,Ytrain)))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"1 - coefficient of determination on validation data:\"+str(1 - mlp_2h100n100n.score(Xval_scaled,Yval)))\n",
    "\n",
    "#let's print the coefficients of the model for the input nodes (but not the bias)\n",
    "print(mlp_2h100n100n.coefs_)\n",
    "\n",
    "#let's print the coefficient for the bias (i.e., the bias)\n",
    "print(mlp_2h100n100n.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that 1 layer (and default number of iterations) works best for this dataset. Let's try 5-fold cross-validation with number of nodes in the hidden layer between 1 and 20.\n",
    "Note that we use train and validation data together, since we are doing cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/vandinfa/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=MLPRegressor(),\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;relu&#x27;],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                11, 12, 13, 14, 15, 16, 17, 18,\n",
       "                                                19, 20],\n",
       "                         &#x27;random_state&#x27;: [1], &#x27;solver&#x27;: [&#x27;lbfgs&#x27;]},\n",
       "             verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=MLPRegressor(),\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;relu&#x27;],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                11, 12, 13, 14, 15, 16, 17, 18,\n",
       "                                                19, 20],\n",
       "                         &#x27;random_state&#x27;: [1], &#x27;solver&#x27;: [&#x27;lbfgs&#x27;]},\n",
       "             verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MLPRegressor(),\n",
       "             param_grid={'activation': ['relu'],\n",
       "                         'hidden_layer_sizes': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                11, 12, 13, 14, 15, 16, 17, 18,\n",
       "                                                19, 20],\n",
       "                         'random_state': [1], 'solver': ['lbfgs']},\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mlp_cv = MLPRegressor()\n",
    "param_grid = {'hidden_layer_sizes': [i for i in range(1,21)],\n",
    "              'activation': ['relu'],\n",
    "              'solver': ['lbfgs'], \n",
    "              'random_state': [numero_di_matricola]\n",
    "             }\n",
    "mlp_GS = GridSearchCV(mlp_cv, param_grid=param_grid, \n",
    "                   cv=5, verbose=True)\n",
    "mlp_GS.fit(Xtrain_and_val_scaled, Ytrain_and_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check what is the best parameter, and compare the best NNs with the linear model (learned on train and validation) on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:  MLPRegressor(hidden_layer_sizes=5, random_state=1, solver='lbfgs')\n",
      "Error (1-R^2) of best model:  0.2144113768928977\n"
     ]
    }
   ],
   "source": [
    "##let's print the best model according to grid search\n",
    "print(\"Best model: \",mlp_GS.best_estimator_)\n",
    "\n",
    "#let's print the error 1-R^2 for the best model\n",
    "print(\"Error (1-R^2) of best model: \",1. - mlp_GS.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let compare the error of the best NN on train and validation and on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error best model on train and validation:  0.1503425230987402\n",
      "Error best model on test data:  0.22765107653274663\n"
     ]
    }
   ],
   "source": [
    "print(\"Error best model on train and validation: \",1. - mlp_GS.best_estimator_.score(Xtrain_and_val_scaled,Ytrain_and_val))\n",
    "print(\"Error best model on test data: \",1. - mlp_GS.best_estimator_.score(Xtest_scaled,Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's learn the linear model on train and validation, and get error (1-R^2) on train and validation and on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - coefficient of determination on training data:0.2715568577139226\n",
      "1 - coefficient of determination on test data:0.3373644878767468\n"
     ]
    }
   ],
   "source": [
    "#LR the linear regression model\n",
    "LR = linear_model.LinearRegression()\n",
    "\n",
    "#fit the model on training data\n",
    "LR.fit(Xtrain_and_val_scaled, Ytrain_and_val)\n",
    "\n",
    "print(\"1 - coefficient of determination on training data:\"+str(1 - LR.score(Xtrain_and_val_scaled,Ytrain_and_val)))\n",
    "print(\"1 - coefficient of determination on test data:\"+str(1 - LR.score(Xtest_scaled,Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: MLPRegressor has several other parameters!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
